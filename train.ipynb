{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMPg3cIafzYB"
      },
      "source": [
        "from time import time\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "import matplotlib\r\n",
        "\r\n",
        "matplotlib.use('Agg')\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from tensorflow.python.keras.models import Model, Sequential\r\n",
        "from tensorflow.python.keras.layers import Input, Embedding, LSTM, GRU, Conv1D, Conv2D, GlobalMaxPool1D, Dense, Dropout\r\n",
        "\r\n",
        "from util import make_w2v_embeddings\r\n",
        "from util import split_and_zero_padding\r\n",
        "from util import ManDist"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbhOmpy3gL8t"
      },
      "source": [
        "\r\n",
        "# File paths\r\n",
        "TRAIN_CSV = './data/train.csv'\r\n",
        "\r\n",
        "# Load training set\r\n",
        "train_df = pd.read_csv(TRAIN_CSV)\r\n",
        "for q in ['question1', 'question2']:\r\n",
        "    train_df[q + '_n'] = train_df[q]\r\n",
        "\r\n",
        "# Make word2vec embeddings\r\n",
        "embedding_dim = 300\r\n",
        "max_seq_length = 20\r\n",
        "use_w2v = True\r\n",
        "\r\n",
        "train_df, embeddings = make_w2v_embeddings(train_df, embedding_dim=embedding_dim, empty_w2v=not use_w2v)\r\n",
        "\r\n",
        "# Split to train validation\r\n",
        "validation_size = int(len(train_df) * 0.1)\r\n",
        "training_size = len(train_df) - validation_size\r\n",
        "\r\n",
        "X = train_df[['question1_n', 'question2_n']]\r\n",
        "Y = train_df['is_duplicate']\r\n",
        "\r\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size)\r\n",
        "\r\n",
        "X_train = split_and_zero_padding(X_train, max_seq_length)\r\n",
        "X_validation = split_and_zero_padding(X_validation, max_seq_length)\r\n",
        "\r\n",
        "# Convert labels to their numpy representations\r\n",
        "Y_train = Y_train.values\r\n",
        "Y_validation = Y_validation.values\r\n",
        "\r\n",
        "# Make sure everything is ok\r\n",
        "assert X_train['left'].shape == X_train['right'].shape\r\n",
        "assert len(X_train['left']) == len(Y_train)\r\n",
        "\r\n",
        "# --\r\n",
        "\r\n",
        "# Model variables\r\n",
        "gpus = 2\r\n",
        "batch_size = 1024 * gpus\r\n",
        "n_epoch = 50\r\n",
        "n_hidden = 50\r\n",
        "\r\n",
        "# Define the shared model\r\n",
        "x = Sequential()\r\n",
        "x.add(Embedding(len(embeddings), embedding_dim,\r\n",
        "                weights=[embeddings], input_shape=(max_seq_length,), trainable=False))\r\n",
        "# CNN\r\n",
        "# x.add(Conv1D(250, kernel_size=5, activation='relu'))\r\n",
        "# x.add(GlobalMaxPool1D())\r\n",
        "# x.add(Dense(250, activation='relu'))\r\n",
        "# x.add(Dropout(0.3))\r\n",
        "# x.add(Dense(1, activation='sigmoid'))\r\n",
        "# LSTM\r\n",
        "x.add(LSTM(n_hidden))\r\n",
        "\r\n",
        "shared_model = x\r\n",
        "\r\n",
        "# The visible layer\r\n",
        "left_input = Input(shape=(max_seq_length,), dtype='int32')\r\n",
        "right_input = Input(shape=(max_seq_length,), dtype='int32')\r\n",
        "\r\n",
        "# Pack it all up into a Manhattan Distance model\r\n",
        "malstm_distance = ManDist()([shared_model(left_input), shared_model(right_input)])\r\n",
        "model = Model(inputs=[left_input, right_input], outputs=[malstm_distance])\r\n",
        "\r\n",
        "if gpus >= 2:\r\n",
        "    # `multi_gpu_model()` is a so quite buggy. it breaks the saved model.\r\n",
        "    model = tf.keras.utils.multi_gpu_model(model, gpus=gpus)\r\n",
        "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\r\n",
        "model.summary()\r\n",
        "shared_model.summary()\r\n",
        "\r\n",
        "# Start trainings\r\n",
        "training_start_time = time()\r\n",
        "malstm_trained = model.fit([X_train['left'], X_train['right']], Y_train,\r\n",
        "                           batch_size=batch_size, epochs=n_epoch,\r\n",
        "                           validation_data=([X_validation['left'], X_validation['right']], Y_validation))\r\n",
        "training_end_time = time()\r\n",
        "print(\"Training time finished.\\n%d epochs in %12.2f\" % (n_epoch,\r\n",
        "                                                        training_end_time - training_start_time))\r\n",
        "\r\n",
        "model.save('./data/SiameseLSTM.h5')\r\n",
        "\r\n",
        "# Plot accuracy\r\n",
        "plt.subplot(211)\r\n",
        "plt.plot(malstm_trained.history['acc'])\r\n",
        "plt.plot(malstm_trained.history['val_acc'])\r\n",
        "plt.title('Model Accuracy')\r\n",
        "plt.ylabel('Accuracy')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\r\n",
        "\r\n",
        "# Plot loss\r\n",
        "plt.subplot(212)\r\n",
        "plt.plot(malstm_trained.history['loss'])\r\n",
        "plt.plot(malstm_trained.history['val_loss'])\r\n",
        "plt.title('Model Loss')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\r\n",
        "\r\n",
        "plt.tight_layout(h_pad=1.0)\r\n",
        "plt.savefig('./data/history-graph.png')\r\n",
        "\r\n",
        "print(str(malstm_trained.history['val_acc'][-1])[:6] +\r\n",
        "      \"(max: \" + str(max(malstm_trained.history['val_acc']))[:6] + \")\")\r\n",
        "print(\"Done.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}